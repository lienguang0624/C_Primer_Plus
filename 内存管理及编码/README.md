# 数据在内存中的存储（二进制形式存储）

&emsp;&emsp;单位换算：

&emsp;&emsp;1Byte = 8 Bit

&emsp;&emsp;1KB = 1024Byte = 210Byte

&emsp;&emsp;1MB = 1024KB = 220Byte


# ASCII编码

&emsp;&emsp;一套规范，计算机公司和软件开发者都必须遵守，这样的一套规范就称为字符集（Character Set）或者字符编码（Character Encoding）。

&emsp;&emsp;ASCII 的标准版本于 1967 年第一次发布，最后一次更新则是在 1986 年，迄今为止共收录了 128 个字符，包含了基本的拉丁字母（英文字母）、阿拉伯数字（也就是 1234567890）、标点符号（,.!等）、特殊符号（@#$%^&等）以及一些具有控制功能的字符（往往不会显示出来）。

&emsp;&emsp;它共收录了 128 个字符，用一个字节中较低的 7 个比特位（Bit）足以表示（27 = 128），所以还会空闲下一个比特位，它就被浪费了。

# 编码GBK和GB2312

&emsp;&emsp;随着计算机发展，各国已经不满足于单纯用ASCII码；

&emsp;&emsp;对于我们来说能在计算机中显示中文字符是至关重要的，所以我们还需要一张关于中文和数字对应的关系表；

&emsp;&emsp;一个字节8位二进制，只能最多表示256个字符，要处理中文显然一个字节是不够的；

&emsp;&emsp;所以我们需要采用两个字节来表示，而且还不能和ASCII编码冲突；

&emsp;&emsp;所以1980年中国制定了GB2312编码，国家简体中文字符集，兼容ASCII；

&emsp;&emsp;1995年制定了GBK编码，GB2312的扩展字符集，支持繁体字，兼容GB2312。

&emsp;&emsp;注：在GBK和GB2312中，一个中文字符占两个字节，16个二进制位，4个十六进制位。

&emsp;&emsp;**如何兼容ASCII：**

&emsp;&emsp;如何区别连在一起的2个字节是代表2个英文字母，还是一个中文汉字呢？

&emsp;&emsp;如果2个字节连在一起，且每个字节的第1位(也就是相当于128的那个2进制位)如果是1，就代表这是个中文，这个首位是128的字节被称为高字节。 也就是2个高字节连在一起，必然就是一个中文。

&emsp;&emsp;因为0-127已经表示了英文的绝大部分字符，128-255是ASCII的扩展表，表示的都是极特殊的字符，一般没什么用。

&emsp;&emsp;所以0-127位ASCII码，GB2312就直接拿来用了。

# 编码Unicode

&emsp;&emsp;全世界有上百种语言，日本把日文编到Shift_JIS里，韩国把韩文编到Euc-kr里；

&emsp;&emsp;各国有各国的标准，就会不可避免地出现冲突，结果就是，在多语言混合的文本中，显示出来会有乱码。

&emsp;&emsp;因此，1991年国际标准组织统一标准字符集，编码Unicode应运而生。

&emsp;&emsp;最常用的是用两个字节表示一个字符（如果要用到非常偏僻的字符，就需要4个字节）

# 编码UTF-8

&emsp;&emsp;如果统一成Unicode编码，乱码问题从此消失了；

&emsp;&emsp;但是，Unicode编码最少用两个字节，ASCII码中英文是一个字节；

&emsp;&emsp;如果文本基本上全部是英文，用Unicode编码需要多一倍存储空间，存储和传输十分费劲。

&emsp;&emsp;1992年创建UTF-8编码，是一种针对Unicode的可变长度字符编码，又称万国码；

&emsp;&emsp;UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节（每8位缩减），从而兼容所有编码，

&emsp;&emsp;英文字符1字节，欧洲字符2字节，中文字符3字节，只有很生僻的字符才会被编码成4-6个字节。